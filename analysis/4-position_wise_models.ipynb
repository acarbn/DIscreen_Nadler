{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of models predicting insertions only from the data of the two neighboring positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import *\n",
    "from Bio.PDB import PDBParser\n",
    "import seaborn as sns \n",
    "from utils.plotting import *\n",
    "from utils.processing import *\n",
    "from utils.model import *\n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import scipy.stats\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "\n",
    "# set styles\n",
    "plt.style.use('./utils/domain_ins.mplstyle')\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dirs\n",
    "base = '/mnt/disk1/jan/DI_screen'\n",
    "in_folder = f'{base}/analysis/input_data'\n",
    "data_folder = f'{base}/analysis/output_datasets'\n",
    "fig_folder = f'{base}/analysis/figures'\n",
    "fasta_sequences = {rec.id : rec.seq for rec in SeqIO.parse(f'{in_folder}/proteins.fasta', 'fasta')}\n",
    "\n",
    "# import data\n",
    "with open(f'{data_folder}/proteins_training.pickle', 'rb') as input:\n",
    "    full_dataset = pickle.load(input)\n",
    "input.close()\n",
    "\n",
    "with open(f'{data_folder}/analysis_dict.pickle', 'rb') as input:\n",
    "    analysis_dict = pickle.load(input)\n",
    "input.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "### Individual proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binerize the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, protein in full_dataset.items():\n",
    "    for key, dataset in protein.items():\n",
    "        dataset.loc[dataset.log>0, 'log']= 1\n",
    "        dataset.loc[dataset.log<=0, 'log'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build classifier:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AraC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = Classifier(full_dataset['AraC']['2'], n_cross_val=5, title_text='AraC_model_context-2')\n",
    "GBC.encode_AA_sequences(fasta_sequences['AraC_s'])\n",
    "GBC.encode_sec_structures()\n",
    "del GBC.dataset['prox_AAs']\n",
    "GBC.clf = GradientBoostingClassifier(n_estimators=150, criterion='friedman_mse', learning_rate=.2, subsample=1, max_depth=3, min_samples_split=4, max_features='sqrt', loss='exponential', random_state=42) \n",
    "model_AraC, X_test_AraC, y_test_AraC, X_train_AraC, y_train_AraC, scores, kf_Ara, scaler = GBC.split_and_train()\n",
    "GBC.metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TVMV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = Classifier(full_dataset['TVMV']['2'], n_cross_val=5, title_text='TVMV_model_context-2')\n",
    "GBC.encode_AA_sequences(fasta_sequences['TVMV_s'])\n",
    "GBC.encode_sec_structures()\n",
    "del GBC.dataset['prox_AAs']\n",
    "model_TVMV, X_test_TVMV, y_test_TVMV, X_train_TVMV, y_train_TVMV, scores, kf_TVMV, scaler = GBC.split_and_train()\n",
    "GBC.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = Classifier(full_dataset['Flp']['2'], n_cross_val=5, title_text='Flp_model_context-2')\n",
    "GBC.encode_AA_sequences(fasta_sequences['Flp_s'])\n",
    "GBC.encode_sec_structures()\n",
    "del GBC.dataset['prox_AAs']\n",
    "model_Flp, X_test_Flp, y_test_Flp, X_train_Flp, y_train_Flp, scores, kf_Flp, scaler = GBC.split_and_train()\n",
    "GBC.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = Classifier(full_dataset['SigF']['2'], n_cross_val=5, title_text='SigF_model_context-2')\n",
    "GBC.encode_AA_sequences(fasta_sequences['SigF_s'])\n",
    "GBC.encode_sec_structures()\n",
    "del GBC.dataset['prox_AAs']\n",
    "model_SigF, X_test_SigF, y_test_SigF, X_train_SigF, y_train_SigF, scores, kf_SigF, scaler = GBC.split_and_train()\n",
    "GBC.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare complete dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add output from transformer insertion model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine datasets to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = full_dataset['AraC'].copy()\n",
    "fasta_sequences_concat = fasta_sequences['AraC_s'] + fasta_sequences['TVMV_s'] + fasta_sequences['Flp_s'] + fasta_sequences['SigF_s']\n",
    "for protein in ['TVMV', 'Flp', 'SigF']:\n",
    "    for idx, dataset in full_dataset[f'{protein}'].items():\n",
    "        final_dataset[idx] = pd.concat([final_dataset[idx], dataset], axis=0)\n",
    "        final_dataset[idx] = final_dataset[idx].reset_index()\n",
    "        del final_dataset[idx]['prox_AAs']\n",
    "        del final_dataset[idx]['index']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = Classifier(final_dataset['2'], n_cross_val=5, title_text='Full_dataset_context-2')\n",
    "random_forest.encode_AA_sequences(fasta_sequences_concat)\n",
    "random_forest.encode_sec_structures()\n",
    "#random_forest.grid_search({\"alpha\": [.00001, .0001, .001], 'penalty':['l1'], 'tol':[1e-3, 5e-4, 1e-4]}, linear_model.Perceptron())\n",
    "model_complete, X_test_complete, y_test_complete, X_train_complete, y_train_complete, scores_complete, kf_complete, scaler_complete = random_forest.split_and_train()\n",
    "random_forest.metrics()\n",
    "scores_complete['test_recall'].mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on AA one-hot-encoding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC_one_hot = Classifier(final_dataset['2']['log'], n_cross_val=5, title_text='Full_dataset_AA')\n",
    "GBC_one_hot.encode_AA_sequences(fasta_sequences_concat)\n",
    "model_AA, X_test_AA, y_test_AA, X_train_AA, y_train_AA, scores_AA, kf_AA, scaler_AA = GBC_one_hot.split_and_train()\n",
    "GBC_one_hot.metrics()\n",
    "scores_AA['test_recall'].mean().round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = Classifier(final_dataset['2'], n_cross_val=5, title_text='Model trained without AA sequence')\n",
    "GBC.encode_AA_sequences(fasta_sequences_concat)\n",
    "GBC.encode_sec_structures()\n",
    "model_complete, X_test_complete, y_test_complete, X_train_complete, y_train_complete, scores_complete, kf_complete, scaler_complete = GBC.split_and_train()\n",
    "GBC.metrics()\n",
    "scores_complete['test_average_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "GBC.clf.fit(X_train_complete, y_train_complete)\n",
    "feature_importance = GBC.clf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(10, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "data = pd.DataFrame([np.array(GBC.dataset.columns)[sorted_idx], feature_importance[sorted_idx]]).T\n",
    "data.columns=['features', 'importance']\n",
    "data.features = data.features.str.replace('_', ' ')\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "g = sns.barplot(data= data.iloc[::-1], y='features', x='importance', color='grey', linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set(xlim=(0, .25))\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Decrease in impurity')\n",
    "plt.title(\"Feature Importance (Mean Decrease in Impurity)\")\n",
    "\n",
    "result = permutation_importance(GBC.clf, X_test_complete, y_test_complete, n_repeats=10, random_state=42, n_jobs=None)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "data = pd.DataFrame(result.importances[sorted_idx]) # TODO concat all columns\n",
    "data.index = np.array(GBC.dataset.columns)[sorted_idx]\n",
    "combined = data.stack()\n",
    "combined = combined.reset_index(level=0)\n",
    "combined.columns = ['features', 'value']\n",
    "combined['features'] = combined['features'].str.replace('_', ' ')\n",
    "plt.subplot(1, 2, 2)\n",
    "g2 = sns.boxplot(data=combined.iloc[::-1], x='value', y='features', color='grey', fliersize=4, linewidth=1.5, whiskerprops={'color':'black'}, flierprops={\"marker\": \"o\", 'color':'black', 'linewidth':0, 'markeredgecolor':'black'}, \n",
    "capprops={'color':'black'}, boxprops={'color':'grey', 'linewidth':1.5, 'edgecolor':'black'}, medianprops={'color':'#E60234'})\n",
    "g2.set(xlim=(-.015, .05))\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Decrease in accuracy')\n",
    "\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "plt.subplots_adjust(hspace=.1, top=.5, bottom=0)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/Classifier_feature_importance.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and assess reduced model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing combination\n",
    "GBC_small = Classifier(final_dataset['2'][['log', 'pLDDT', 'Linker_idx_Suyama',\n",
    "       'KLD', 'Insert_frequency','Deletion_frequency', 'Mean_ins_len']], n_cross_val=5, title_text='Model trained on selected features')\n",
    "model_, X_test_, y_test_, X_train_, y_train_, scores_, kf_, scaler_ = GBC_small.split_and_train()\n",
    "GBC_small.metrics()\n",
    "scores_['test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GBC_small.clf.fit(X_train_, y_train_)\n",
    "feature_importance = GBC_small.clf.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "data = pd.DataFrame([np.array(GBC_small.dataset.columns)[sorted_idx], feature_importance[sorted_idx]]).T\n",
    "data.columns=['features', 'importance']\n",
    "data.features = data.features.str.replace('_', ' ')\n",
    "g = sns.barplot(data= data.iloc[::-1], y='features', x='importance', color='grey', linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set(xlim=(0, .35))\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Decrease in impurity')\n",
    "plt.title(\"Feature Importance (Mean Decrease in Impurity)\")\n",
    "\n",
    "result = permutation_importance(GBC_small.clf, X_test_, y_test_, n_repeats=10, random_state=42, n_jobs=None)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "data = pd.DataFrame(result.importances[sorted_idx]) \n",
    "data.index = np.array(random_forest.dataset.columns)[sorted_idx]\n",
    "combined = data.stack()\n",
    "combined = combined.reset_index(level=0)\n",
    "combined.columns = ['features', 'value']\n",
    "combined['features'] = combined['features'].str.replace('_', ' ')\n",
    "plt.subplot(1, 2, 2)\n",
    "g2 = sns.boxplot(data=combined.iloc[::-1], x='value', y='features', color='grey', fliersize=4, linewidth=1.5, whiskerprops={'color':'black'}, flierprops={\"marker\": \"o\", 'color':'black', 'linewidth':0, 'markeredgecolor':'black'}, \n",
    "capprops={'color':'black'}, boxprops={'color':'grey', 'linewidth':1.5, 'edgecolor':'black'}, medianprops={'color':'#E60234'})\n",
    "g2.set(xlim=(-.03, .05))\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Decrease in accuracy')\n",
    "\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "plt.subplots_adjust(hspace=.1, top=.5, bottom=0)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{fig_folder}/Classifier_feature_importance_less_features.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_predictions = model_complete.predict_proba(X_test_complete)\n",
    "model_predictions = model_predictions[:,1]\n",
    "random_baseline = np.random.randint(2, size=len(X_test_complete))\n",
    "loops_baseline = X_test_complete[:,0]\n",
    "asa_baseline = X_test_complete[:,23]\n",
    "hydrophobicity_baseline = X_test_complete[:,28]\n",
    "baseline_auroc = []\n",
    "baseline_pr = []\n",
    "for idx, mod in enumerate([model_predictions, random_baseline, loops_baseline, asa_baseline, hydrophobicity_baseline]):\n",
    "    baseline_auroc.append(metrics.roc_auc_score(y_test_complete, mod)) \n",
    "    baseline_pr.append(metrics.average_precision_score(y_test_complete, mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Classifier', 'Random baseline', 'Loops', 'Surface exposure', 'Hydrophobicity']\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "g = sns.barplot(x=names, y=baseline_auroc, palette=['#87001D', 'grey', 'grey', 'grey', 'grey'], linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set_xticklabels(names, rotation=90)\n",
    "g.set(ylabel='AUROC')\n",
    "g.set_title(label='AUROC comparison to baselines', fontsize=15)\n",
    "plt.savefig(f\"{fig_folder}/baselines_auroc.svg\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "g = sns.barplot(x=names, y=baseline_pr, palette=['#174950', 'grey', 'grey', 'grey', 'grey'], linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set_xticklabels(names, rotation=90)\n",
    "g.set(ylabel='Average precision')\n",
    "g.set_title(label='Precision comparison to baselines', fontsize=15)\n",
    "plt.savefig(f\"{fig_folder}/baselines_ap.svg\")\n",
    "plt.show()\n",
    "print(baseline_auroc)\n",
    "print(baseline_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_predictions = model_complete.predict_proba(X_test_complete)\n",
    "model_predictions = model_predictions[:,1]\n",
    "test_data_concat = np.c_[model_predictions, X_test_complete]\n",
    "baseline_auroc = []\n",
    "baseline_pr = []\n",
    "for idx in range(test_data_concat.shape[1]):\n",
    "    baseline_auroc.append(metrics.roc_auc_score(y_test_complete, test_data_concat[:,idx])) \n",
    "    baseline_pr.append(metrics.average_precision_score(y_test_complete, test_data_concat[:,idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Classifier'] + GBC.dataset.columns.to_list()\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "g = sns.barplot(x=names, y=baseline_auroc, color='grey', linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set_xticklabels(names, rotation=90)\n",
    "g.set(ylabel='AUROC')\n",
    "g.set_title(label='AUROC comparison to baselines', fontsize=15)\n",
    "g.set(xlim=(-.6, 45.7))\n",
    "plt.savefig(f\"{fig_folder}/baselines_auroc_full.svg\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "g = sns.barplot(x=names, y=baseline_pr, color='grey', linewidth=1.5, capsize=.2, errcolor=\"black\", edgecolor=\"black\")\n",
    "g.set_xticklabels(names, rotation=90)\n",
    "g.set(ylabel='Average precision')\n",
    "g.set_title(label='Precision comparison to baselines', fontsize=15)\n",
    "plt.savefig(f\"{fig_folder}/baselines_ap_full.svg\")\n",
    "g.set(xlim=(-.6, 45.7))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('dipseq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "039b150e2a501b43cb42c0bb6f96961eb02ac0d168d7989199fe3219f1545794"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
