{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of AF predictions with regard to domain insertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Bio\n",
    "from Bio import SeqUtils\n",
    "from Bio.PDB import *\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio import pairwise2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib as matplotlib\n",
    "\n",
    "\n",
    "# set styles\n",
    "plt.style.use('./utils/domain_ins.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and set dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general input folder\n",
    "base = '/work/projects/project01640/jm/domain_insertion/DI_screen'\n",
    "data_folder = f'{base}/analysis/output_datasets'\n",
    "fig_folder = f'{base}/analysis/figures'\n",
    "prot_path = f'{base}/analysis/input_data/hybrid_prediction_screen'\n",
    "\n",
    "# impoert analysis dict\n",
    "with open(f'{data_folder}/analysis_dict.pickle', 'rb') as input:\n",
    "    analysis_dict = pickle.load(input)\n",
    "input.close()\n",
    "\n",
    "#import datasets\n",
    "with open(f'{data_folder}/proteins_training.pickle', 'rb') as input:\n",
    "    full_dataset = pickle.load(input)\n",
    "input.close()\n",
    "\n",
    "protein_combinations = [['AraC', 'PDZ']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pLDDT(structure):\n",
    "    '''\n",
    "    Extracts the pLDDT score for the given structure\n",
    "    '''\n",
    "    pLDDT_score = []\n",
    "    for chain in structure[0]: \n",
    "        for residue in chain:\n",
    "            for atom in residue:\n",
    "                if atom.full_id[4][0] == 'CA':\n",
    "                    pLDDT_score.append(atom.bfactor)\n",
    "    return pLDDT_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create protein sequence df\n",
    "import glob\n",
    "positions = pd.Series(glob.glob('./input_data/hybrid_prediction_screen/*.pdb'))\n",
    "positions = positions.str.split('/', expand=True)[3]\n",
    "positions = positions.str.split('_', expand=True).iloc[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the pdb files\n",
    "parser = PDBParser()\n",
    "PDBs = {}\n",
    "for combination in protein_combinations:\n",
    "    PDBs[f'{combination[0]}_{combination[1]}'] = {}\n",
    "\n",
    "for idx, pos in positions.iterrows():\n",
    "    protein = pos[0]\n",
    "    position = pos[1]\n",
    "    domain = pos[2]\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}'] = {'structure':{}, 'pLDDT':{}, 'RMSD':{}}\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}'] = {'structure':{}, 'pLDDT':{}, 'RMSD':{}}\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['structure'] = parser.get_structure(position, f'{prot_path}/{protein}_{position}_{domain}_unrelaxed_rank_1_model_3.pdb')\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['pLDDT'] = get_pLDDT(PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['structure'])\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['structure'] = parser.get_structure(position, f'{prot_path}/{protein}_{position}_{domain}_unrelaxed_rank_1_model_3.pdb')\n",
    "    PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['pLDDT'] = get_pLDDT(PDBs[f'{protein}_{domain}'][f'{protein}_{position}_{domain}']['structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the current dataset to pickle\n",
    "with open(f'{data_folder}/PDBs.pickle', 'wb') as f:\n",
    "    pickle.dump(PDBs, f) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the structures of the WT proteins\n",
    "#AraC_wt_structure = parser.get_structure('AraC', f'/work/projects/project01640/jm/domain_insertion/pdb_files/AraC_AF.pdb')\n",
    "parser = PDBParser()\n",
    "WT_proteins = {}\n",
    "protein_names = ['AraC', 'PDZ']\n",
    "for protein in protein_names:\n",
    "    WT_proteins[protein] = {}\n",
    "    WT_proteins[protein]['structure'] = parser.get_structure(protein, f'{prot_path}/{protein}_unrelaxed_rank_1_model_3.pdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_seqs = {}\n",
    "for combination in protein_combinations:\n",
    "    fusion_seqs[f'{combination[0]}_{combination[1]}'] = {}\n",
    "\n",
    "#get some data for the structure alignment\n",
    "for protein in protein_names:\n",
    "    WT_proteins[protein]['seq'] = ''\n",
    "    for res in WT_proteins[protein]['structure'].get_residues():\n",
    "        WT_proteins[protein]['seq'] += SeqUtils.IUPACData.protein_letters_3to1[res.get_resname().title()]\n",
    "\n",
    "for protein in protein_names:\n",
    "    WT_proteins[protein]['res'] = []\n",
    "    for res in WT_proteins[protein]['structure'].get_residues():\n",
    "        WT_proteins[protein]['res'].append(res['CA'])\n",
    "\n",
    "for combination in protein_combinations:\n",
    "    try:\n",
    "        for idx, AA in enumerate(WT_proteins[combination[0]]['seq']):\n",
    "            fusion_seqs[f'{combination[0]}_{combination[1]}'][f'{combination[0]}_{AA}{idx+1}_{combination[1]}'] = WT_proteins[combination[0]]['seq'][:idx+1] + WT_proteins[combination[1]]['seq'] + WT_proteins[combination[0]]['seq'][idx+1:]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMS = {}\n",
    "for comb in protein_combinations:\n",
    "    RMS[f'{comb[0]}_{comb[1]}'] = {}\n",
    "    RMS[f'{comb[0]}_{comb[1]}'][f'{comb[0]}_rms_values'] = []\n",
    "    RMS[f'{comb[0]}_{comb[1]}'][f'{comb[1]}_rms_values'] = []\n",
    "\n",
    "y = 0\n",
    "for combination, comb_dict in PDBs.items():\n",
    "        #if combination == 'AraC_PDZ':\n",
    "        for variant_name, variant in comb_dict.items():\n",
    "            # align the fusion protein to the parent protein and determin insertion\n",
    "            alignments = pairwise2.align.globalxs(WT_proteins[combination.split('_')[0]]['seq'], fusion_seqs[combination][variant_name], -1000, -1)\n",
    "            start = alignments[0][0].find('-')\n",
    "            end = alignments[0][0].rfind('-')\n",
    "            insert_alignment = range(start +1, end +2)\n",
    "            \n",
    "            #split pLDDT score by parent and insert\n",
    "            variant['pLDDT_insert'] = variant['pLDDT'][start:end+1]\n",
    "            variant['pLDDT_parent'] = variant['pLDDT'][:start] + variant['pLDDT'][end+1:]\n",
    "            #print(variant['pLDDT_insert'])\n",
    "            # gather th coordinates for the alignment\n",
    "            candidate_res_ins = []\n",
    "            candidate_res_par = []\n",
    "            variant['RMSD_parent'] = []\n",
    "            variant['RMSD_insert'] = []\n",
    "            for res in variant['structure'].get_residues():            \n",
    "                if res.get_id()[1] in insert_alignment:\n",
    "                    candidate_res_ins.append(res['CA'])\n",
    "                else: \n",
    "                    candidate_res_par.append(res['CA'])\n",
    "\n",
    "            # perform structure alignment and get rms\n",
    "            super_imposer = Bio.PDB.Superimposer()\n",
    "            super_imposer.set_atoms(WT_proteins[combination.split('_')[1]]['res'], candidate_res_ins)\n",
    "            super_imposer.apply(variant['structure'].get_atoms())\n",
    "            RMS[f'{combination.split(\"_\")[0]}_{combination.split(\"_\")[1]}'][f'{combination.split(\"_\")[1]}_rms_values'].append(super_imposer.rms)\n",
    "            for idx, atom in enumerate(candidate_res_ins):\n",
    "                variant['RMSD_insert'].append(atom - WT_proteins[combination.split('_')[1]]['res'][idx])\n",
    "\n",
    "            super_imposer.set_atoms(WT_proteins[combination.split('_')[0]]['res'], candidate_res_par)\n",
    "            super_imposer.apply(variant['structure'].get_atoms())\n",
    "            RMS[f'{combination.split(\"_\")[0]}_{combination.split(\"_\")[1]}'][f'{combination.split(\"_\")[0]}_rms_values'].append(super_imposer.rms)\n",
    "            for idx, atom in enumerate(candidate_res_par):\n",
    "                    variant['RMSD_parent'].append(atom - WT_proteins[combination.split('_')[0]]['res'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y, name):\n",
    "    sns.set_style(\"ticks\")\n",
    "    data = pd.DataFrame(list(zip(list(x),y)), columns=['enrichment', 'property'])\n",
    "    data.dropna(inplace=True)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.rcParams['axes.linewidth'] = 2\n",
    "    g = sns.regplot(data=data, x='property', y='enrichment', color='#008080', ci=None, \n",
    "        scatter_kws={'alpha':.3, 'linewidth':0}, line_kws={'alpha':1})\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Log2 variant enrichment\")\n",
    "    sns.despine()\n",
    "    #g.legend.remove()\n",
    "    plt.title(f\"Correlation between enrichment score and {name}\")\n",
    "\n",
    "# Plot correlations between structures and enrichments\n",
    "correlation(full_dataset['AraC']['2']['log'], RMS['AraC_PDZ']['PDZ_rms_values'], 'RMSD PDZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data to df and sort by sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pack data into dfs\n",
    "predict_data = {}\n",
    "for combination in protein_combinations:\n",
    "    predict_data[f'{combination[0]}_{combination[1]}'] = {}\n",
    "    predict_data[f'{combination[0]}_{combination[1]}']['pLDDT_parent'] = {}\n",
    "    predict_data[f'{combination[0]}_{combination[1]}']['pLDDT_insert'] = {}\n",
    "    predict_data[f'{combination[0]}_{combination[1]}']['RMSD_parent'] = {}\n",
    "    predict_data[f'{combination[0]}_{combination[1]}']['RMSD_insert'] = {}\n",
    "    for variant_name, variant in PDBs[f'{combination[0]}_{combination[1]}'].items():\n",
    "        predict_data[f'{combination[0]}_{combination[1]}']['pLDDT_parent'][variant_name] = variant['pLDDT_parent']\n",
    "        predict_data[f'{combination[0]}_{combination[1]}']['pLDDT_insert'][variant_name] = variant['pLDDT_insert']\n",
    "        predict_data[f'{combination[0]}_{combination[1]}']['RMSD_parent'][variant_name] = variant['RMSD_parent']\n",
    "        predict_data[f'{combination[0]}_{combination[1]}']['RMSD_insert'][variant_name] = variant['RMSD_insert']\n",
    "    #get residue order\n",
    "    predict_data[f'{combination[0]}_{combination[1]}'][f'{combination[0]}_AA'] = []\n",
    "    for position, AA in enumerate(WT_proteins[combination[0]]['seq']):\n",
    "        predict_data[f'{combination[0]}_{combination[1]}'][f'{combination[0]}_AA'].append(f'{AA}{position + 1}')\n",
    "    \n",
    "    #create and process dfs\n",
    "    for name, dataset in predict_data[f'{combination[0]}_{combination[1]}'].items():\n",
    "        if name != f'{combination[0]}_AA':\n",
    "            dataset = pd.DataFrame.from_dict(dataset)\n",
    "            dataset.columns = dataset.columns.str.replace(f'{combination[0]}_','')\n",
    "            dataset.columns = dataset.columns.str.replace(f'_{combination[1]}','')\n",
    "            predict_data[f'{combination[0]}_{combination[1]}'][name] = dataset.reindex(predict_data[f'{combination[0]}_{combination[1]}'][f'{combination[0]}_AA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot position-wise correlations\n",
    "for combination, data_dict in predict_data.items():\n",
    "    for name, dataset in data_dict.items():\n",
    "        if name != f'{combination.split(\"_\")[0]}_AA':\n",
    "            print(name)\n",
    "            sns.set_style(\"ticks\")\n",
    "            plt.figure(figsize=(10,10))\n",
    "            ax =sns.heatmap(data=dataset.T, cmap=sns.light_palette('#174950', as_cmap=True), square=True, robust=False, vmin=0,# vmax=100,\n",
    "                            cbar_kws={'label': name.split('_')[0], 'shrink':.3, 'orientation':'horizontal', 'ticks': [0, 20, 40, 60, 80, 100], 'extend':'neither'})\n",
    "            plt.title(f\"Heatmap: {combination}; {name}\", fontsize=20, y=1.01)\n",
    "            for _, spine in ax.spines.items():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_linewidth(2)\n",
    "            ax.yaxis.set_tick_params(width=2)\n",
    "            ax.xaxis.set_tick_params(width=2)\n",
    "            ax.set_xticks(np.arange(.5, len(dataset.iloc[:,0]) +.5, 10))\n",
    "            ax.set_xticklabels(np.arange(1, len(dataset.iloc[:,0])+1, 10), fontsize=10)\n",
    "            ax.set_yticks(np.arange(.5, len(dataset.iloc[0,:]) +.5, 10))\n",
    "            ax.set_yticklabels(dataset.columns[::10], fontsize=10)\n",
    "            ax.set_xlabel(\"Sequence\", fontsize = 15)\n",
    "            ax.set_ylabel(\"Insertion site\", fontsize = 15)\n",
    "            plt.savefig(f\"{fig_folder}/feature_correlation_{combination}_{name}.svg\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "#sns.diverging_palette(187, 10, s=100, l=25, as_cmap=True)\n",
    "#sns.light_palette('#174950', as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump the current dataset to pickle\n",
    "with open(f'{data_folder}/predict_data.pickle', 'wb') as f:\n",
    "    pickle.dump(predict_data, f) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {}\n",
    "for pair, data_dict in predict_data.items():\n",
    "        for feature, dataset in data_dict.items():\n",
    "            correlations_list = []\n",
    "            if isinstance(dataset, pd.DataFrame):\n",
    "                for position, values in dataset.iterrows():\n",
    "                    x = pd.Series((analysis_dict[f\"AraC_PDZ\"]['12']['log'] + analysis_dict[f\"AraC_PDZ\"]['22']['log'])/2)\n",
    "                    correlations_list.append(values.reset_index(drop=True).corr(x, method='spearman'))\n",
    "                correlations[f'{pair}_{feature}'] = correlations_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_line_plot(dataset, title):\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax =sns.lineplot(data=pd.DataFrame(dataset), legend=False, palette={'#174950'})\n",
    "    plt.title(title)\n",
    "    sns.despine()\n",
    "    ax.set(xlim=(0, len(dataset)))\n",
    "    ax.set_xlabel(\"Sequence\", fontsize = 15)\n",
    "    ax.set_ylabel(\"Spearman's r\", fontsize = 15)\n",
    "    plt.savefig(f\"{fig_folder}/feature_correlation_{name}.svg\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for name, dataset in correlations.items():\n",
    "    insertion_line_plot(dataset, f\"Correlation between insertion score and {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('dipseq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "039b150e2a501b43cb42c0bb6f96961eb02ac0d168d7989199fe3219f1545794"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
